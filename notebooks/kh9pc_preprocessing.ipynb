{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2200e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de570a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hipp\n",
    "import os\n",
    "import usgsxplore\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba530b7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fc7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_DIRECTORY = Path(\"/home/godinlu/github/hipp/notebooks/data/kh9pc\")\n",
    "RAW_IMAGES = PROJECT_DIRECTORY / \"raw_images\"\n",
    "JOINED_IMAGES = PROJECT_DIRECTORY / \"joined_images\"\n",
    "PREPROCESSED_IMAGES = PROJECT_DIRECTORY / \"preprocessed_images\"\n",
    "QC_DIRECTORY = PROJECT_DIRECTORY / \"qc_dir\"\n",
    "\n",
    "QUICKVIEW_FACTOR = 0.05\n",
    "MAX_WORKERS = 4\n",
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b9125",
   "metadata": {},
   "source": [
    "## Step 1 : Download raw images\n",
    "\n",
    "To download the raw images we will use [`usgsxplore`](https://github.com/adehecq/usgs_explorer) which is an python interface to the [USGS M2M API](https://m2m.cr.usgs.gov/) to search and download data available from the [Earth Explorer](https://earthexplorer.usgs.gov/) platform.\n",
    "We will download 2 images and each image is separated in 10 or 12 parts : `_a`, `_b`, `_c`, ...\n",
    "The total downloading size is 16 Go, so it can take a will. Further more, the stagging links from the [USGS M2M API](https://m2m.cr.usgs.gov/) can take some time.\n",
    "The downloading include already the extracting of tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a37e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.getenv(\"USGS_USERNAME\") or input(\"Enter your USGS username: \")\n",
    "token = os.getenv(\"USGS_TOKEN\") or input(\"Enter your USGS token: \")\n",
    "\n",
    "entity_ids = [\"D3C1214-100097A014\", \"D3C1214-100097A015\"]\n",
    "\n",
    "api = usgsxplore.API(username, token)\n",
    "api.download(\"declassiii\", entity_ids, output_dir=RAW_IMAGES)\n",
    "api.logout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e0734",
   "metadata": {},
   "outputs": [],
   "source": [
    "hipp.tools.optimize_geotifs(RAW_IMAGES)\n",
    "hipp.tools.generate_quickviews(RAW_IMAGES, QUICKVIEW_FACTOR, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101c03b",
   "metadata": {},
   "source": [
    "## Step 2 : Joining Images\n",
    "\n",
    "The first step of the preprocessing pipeline is to **join multiple image tiles** into a single, continuous image. This process is necessary because **KH9 PC images are typically split into 10-12 separate parts**, each approximately **1 GB in size**, due to their large original resolution.\n",
    "\n",
    "However, **joining these image parts is not straightforward**, primarily because there is a **slight overlap between adjacent tiles**. \n",
    "\n",
    "To accurately reconstruct the full image, we need to perform the following steps:\n",
    "\n",
    "1. **Detect keypoints (interest points)** along the **right border** of the first image part.\n",
    "2. Detect corresponding keypoints along the **left border** of the next image part.\n",
    "3. **Match these keypoints** using a feature-matching algorithm to find candidate correspondences.\n",
    "4. Use **RANSAC (Random Sample Consensus)** to filter out mismatched or erroneous correspondences (i.e., outliers).\n",
    "5. Estimate a **relative geometric transformation** (typically a translation or affine transform) to correctly align the second image with the first.\n",
    "6. Apply this transformation and **merge the two parts** into a larger composite image.\n",
    "\n",
    "This process is repeated sequentially for all image parts, progressively building up the full image mosaic.\n",
    "\n",
    "To perform that 2 functions exists:\n",
    "- `join_images_asp` : which will use [`image_mosaic`](https://stereopipeline.readthedocs.io/en/latest/tools/image_mosaic.html) program from Ames Stereo Pipeline. This function is much more safer but it requiered to install ASP and the command need to be visible in your path.\n",
    "- `join_images` : is a pure Python implementation that replicates the same processing steps, it's faster an generate some qc plots. (8 min vs 40 min for asp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38698b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hipp.kh9pc.join_images_asp(RAW_IMAGES, JOINED_IMAGES)\n",
    "\n",
    "hipp.kh9pc.join_images(RAW_IMAGES, JOINED_IMAGES, OVERWRITE, max_workers=MAX_WORKERS)\n",
    "\n",
    "hipp.tools.generate_quickviews(JOINED_IMAGES, QUICKVIEW_FACTOR, max_workers=MAX_WORKERS, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7dbbb",
   "metadata": {},
   "source": [
    "## Step 3: Processing the Joined Image Using Collimation Lines\n",
    "\n",
    "The goal of this step is to correct distortions and crop the image based on the top and bottom collimation lines. This process is essential because the joined image contains both a region of interest (ROI) and a background area. The ROI may not be perfectly centered or aligned within the background, so we aim to isolate and retain only the ROI.\n",
    "\n",
    "This step involves the following sub-processes:\n",
    "\n",
    "- **Estimate both collimation lines using a polynomial model:**\n",
    "  - Vertically scan the image to detect intensity peaks.\n",
    "  - For each column, keep the peak with the highest prominence.\n",
    "  - Fit a second-degree polynomial using RANSAC on the detected peaks.\n",
    "\n",
    "- **Estimate the vertical edges (x₁ and x₂) of the ROI:**\n",
    "  - Horizontally scan the image and record points where intensity values exceed a defined background threshold.\n",
    "  - Fit constant lines using RANSAC to estimate x₁ and x₂.\n",
    "\n",
    "- **Create source and target grid points:**\n",
    "  - Generate the source points by sampling along both detected collimation lines, forming a grid between them.\n",
    "  - Generate the target points by sampling along the theoretical collimation lines (spaced by 21,770 px) and building a corresponding grid.\n",
    "\n",
    "- **Remap the image using Thin Plate Spline (TPS):**\n",
    "  - Compute the TPS transformation using the source and target points, then apply it to the image.\n",
    "  - To reduce computation time, calculate the transformation coordinates at a lower resolution with TPS and upscale them using a bivariate spline interpolation for the full resolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c3f50",
   "metadata": {},
   "source": [
    "This all pipeline is based on collimations lines detection. And it can appends to detect wrong lines with wrong padding, so make sure both collimation lines are correct before next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0ed1755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collimation rectification for D3C1214-100097A014.tif : \n",
      "\t-[1/4] Estimation of collimation lines...\n",
      "\t-[2/4] Detection of vertical lines...\n",
      "\t-[3/4] Warping image (can take some times)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D3C1214-100097A014.tif remapping: 100%|████████████████████████████████████████████████████████████████████████████████████████| 129/129 [14:35<00:00,  6.79s/block]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-[4/4] Estimation of collimation lines after transformation...\n",
      "Collimation rectification for D3C1214-100097A015.tif : \n",
      "\t-[1/4] Estimation of collimation lines...\n",
      "\t-[2/4] Detection of vertical lines...\n",
      "\t-[3/4] Warping image (can take some times)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D3C1214-100097A015.tif remapping: 100%|████████████████████████████████████████████████████████████████████████████████████████| 126/126 [17:25<00:00,  8.30s/block]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-[4/4] Estimation of collimation lines after transformation...\n"
     ]
    }
   ],
   "source": [
    "hipp.kh9pc.iter_collimation_rectification(JOINED_IMAGES, PREPROCESSED_IMAGES, QC_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
