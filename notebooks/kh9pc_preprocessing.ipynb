{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2200e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8de570a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hipp\n",
    "import os\n",
    "import usgsxplore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba530b7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fc7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_DIRECTORY = \"data/kh9pc\"\n",
    "RAW_IMAGES = os.path.join(PROJECT_DIRECTORY, \"raw_images\")\n",
    "JOINED_IMAGES = os.path.join(PROJECT_DIRECTORY, \"joined_images\")\n",
    "PREPROCESSED_IMAGES = os.path.join(PROJECT_DIRECTORY, \"preprocessed_images\")\n",
    "CROPPING_BORDERS_FILE = os.path.join(PROJECT_DIRECTORY, \"cropping_borders.csv\")\n",
    "\n",
    "QUICKVIEW_FACTOR = 0.05\n",
    "\n",
    "# for the downloading via USGS\n",
    "username = os.getenv(\"USGS_USERNAME\") or input(\"Enter your USGS username: \")\n",
    "token = os.getenv(\"USGS_TOKEN\") or input(\"Enter your USGS token: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b9125",
   "metadata": {},
   "source": [
    "## Step 1 : Download raw images\n",
    "\n",
    "To download the raw images we will use [`usgsxplore`](https://github.com/adehecq/usgs_explorer) which is an python interface to the [USGS M2M API](https://m2m.cr.usgs.gov/) to search and download data available from the [Earth Explorer](https://earthexplorer.usgs.gov/) platform.\n",
    "We will download 2 images and each image is separated in 10 or 12 parts : `_a`, `_b`, `_c`, ...\n",
    "The total downloading size is 16 Go, so it can take a will. Further more, the stagging links from the [USGS M2M API](https://m2m.cr.usgs.gov/) can take some time.\n",
    "The downloading include already the extracting and the optimizing of tif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a37e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating quickviews: 0image [00:00, ?image/s]\n"
     ]
    }
   ],
   "source": [
    "entity_ids = [\"D3C1214-100097A014\", \"D3C1214-100097A015\"]\n",
    "\n",
    "api = usgsxplore.API(username, token)\n",
    "api.download(\"declassiii\", entity_ids, output_dir=RAW_IMAGES)\n",
    "api.logout()\n",
    "\n",
    "hipp.tools.generate_quickviews(RAW_IMAGES, QUICKVIEW_FACTOR, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f101c03b",
   "metadata": {},
   "source": [
    "## Step 2 : Joining Images\n",
    "\n",
    "The first step of the preprocessing pipeline is to **join multiple image tiles** into a single, continuous image. This process is necessary because **KH9 PC images are typically split into 10-12 separate parts**, each approximately **1 GB in size**, due to their large original resolution.\n",
    "\n",
    "However, **joining these image parts is not straightforward**, primarily because there is a **slight overlap between adjacent tiles**. \n",
    "\n",
    "To accurately reconstruct the full image, we need to perform the following steps:\n",
    "\n",
    "1. **Detect keypoints (interest points)** along the **right border** of the first image part.\n",
    "2. Detect corresponding keypoints along the **left border** of the next image part.\n",
    "3. **Match these keypoints** using a feature-matching algorithm to find candidate correspondences.\n",
    "4. Use **RANSAC (Random Sample Consensus)** to filter out mismatched or erroneous correspondences (i.e., outliers).\n",
    "5. Estimate a **relative geometric transformation** (typically a translation or affine transform) to correctly align the second image with the first.\n",
    "6. Apply this transformation and **merge the two parts** into a larger composite image.\n",
    "\n",
    "This process is repeated sequentially for all image parts, progressively building up the full image mosaic.\n",
    "\n",
    "To perform that the function `join_images` will use the [`image_mosaic`](https://stereopipeline.readthedocs.io/en/latest/tools/image_mosaic.html) program from Ames Stereo Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38698b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mosaicking data/kh9pc/joined_images/D3C1214-100097A014.tif with 10 tiles...\n",
      "\n",
      "image_mosaic data/kh9pc/raw_images/D3C1214-100097A014_a.tif data/kh9pc/raw_images/D3C1214-100097A014_b.tif data/kh9pc/raw_images/D3C1214-100097A014_c.tif data/kh9pc/raw_images/D3C1214-100097A014_d.tif data/kh9pc/raw_images/D3C1214-100097A014_e.tif data/kh9pc/raw_images/D3C1214-100097A014_f.tif data/kh9pc/raw_images/D3C1214-100097A014_g.tif data/kh9pc/raw_images/D3C1214-100097A014_h.tif data/kh9pc/raw_images/D3C1214-100097A014_i.tif data/kh9pc/raw_images/D3C1214-100097A014_j.tif --ot byte --overlap-width 3000 --threads 0 -o data/kh9pc/joined_images/D3C1214-100097A014.tif\n",
      "\n",
      "Mosaicking data/kh9pc/joined_images/D3C1214-100097A015.tif with 12 tiles...\n",
      "\n",
      "image_mosaic data/kh9pc/raw_images/D3C1214-100097A015_a.tif data/kh9pc/raw_images/D3C1214-100097A015_b.tif data/kh9pc/raw_images/D3C1214-100097A015_c.tif data/kh9pc/raw_images/D3C1214-100097A015_d.tif data/kh9pc/raw_images/D3C1214-100097A015_e.tif data/kh9pc/raw_images/D3C1214-100097A015_f.tif data/kh9pc/raw_images/D3C1214-100097A015_g.tif data/kh9pc/raw_images/D3C1214-100097A015_h.tif data/kh9pc/raw_images/D3C1214-100097A015_i.tif data/kh9pc/raw_images/D3C1214-100097A015_j.tif data/kh9pc/raw_images/D3C1214-100097A015_k.tif data/kh9pc/raw_images/D3C1214-100097A015_l.tif --ot byte --overlap-width 3000 --threads 0 -o data/kh9pc/joined_images/D3C1214-100097A015.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating quickviews: 0image [00:00, ?image/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating quickviews: 0image [00:00, ?image/s]\n"
     ]
    }
   ],
   "source": [
    "hipp.kh9pc.join_images(RAW_IMAGES, JOINED_IMAGES, dryrun=True, overwrite=True)\n",
    "hipp.tools.generate_quickviews(JOINED_IMAGES, QUICKVIEW_FACTOR, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80946cfb",
   "metadata": {},
   "source": [
    "## Step 3 : Define manualy all cropping points\n",
    "\n",
    "The function `hipp.kh9pc.select_all_cropping_points` allow you to manually select corners of the region of interest.\n",
    "- Split each image with 5 x 20 blocks (parameters `grid_shape`)\n",
    "- open each corners block in an interactive window where you can Ctrl + Click on the corner\n",
    "- save all results in the csv file (`csv_file`)\n",
    "\n",
    "**Note** :\n",
    "- This function dont overwrite existing data in the csv file (if existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f83e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hipp.kh9pc.select_all_cropping_points(JOINED_IMAGES, CROPPING_BORDERS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e7c19",
   "metadata": {},
   "source": [
    "## Step 4 : Cropping image to remove borders\n",
    "\n",
    "With the previously generated cropping points, we can use the `hipp.kh9pc.crop_images` to finish the preprocessing.\n",
    "For each image in the input directory, this function looks up its corresponding cropping points in the CSV file, rotates the image to align the top edge, crops it accordingly, and saves the result in the output directory.\n",
    "\n",
    "**Note :**\n",
    "\n",
    "- Images will have different size according to their coresponding croppings points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307069d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 'D3C1214-100097A015' :\n",
      "\t- Cropping points : [(1541, 1433), (345531, 1737), (345485, 23420), (1551, 23125)]\n",
      "\t- Output size : (343990, 21692)\n",
      "\t- Transformation matrix : \n",
      "[[ 9.99999609e-01  8.83746275e-04 -1.54195769e+03]\n",
      " [-8.83746275e-04  9.99999609e-01 -1.43126755e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[D3C1214-100097A015] warping: 100%|██████████| 114240/114240 [07:49<00:00, 243.40block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Image saved at 'data/kh9pc/preprocessed_images/D3C1214-100097A015.tif'\n",
      "\n",
      "Image 'D3C1214-100097A014' :\n",
      "\t- Cropping points : [(4639, 1662), (350174, 1850), (350061, 23655), (4706, 23456)]\n",
      "\t- Output size : (345535, 21805)\n",
      "\t- Transformation matrix : \n",
      "[[ 9.99999852e-01  5.44083732e-04 -4.63978644e+03]\n",
      " [-5.44083732e-04  9.99999852e-01 -1.65931988e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[D3C1214-100097A014] warping: 100%|██████████| 116100/116100 [07:50<00:00, 246.81block/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Image saved at 'data/kh9pc/preprocessed_images/D3C1214-100097A014.tif'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating quickviews: 100%|██████████| 2/2 [00:56<00:00, 28.12s/image]\n"
     ]
    }
   ],
   "source": [
    "hipp.kh9pc.crop_images(JOINED_IMAGES, CROPPING_BORDERS_FILE, PREPROCESSED_IMAGES)\n",
    "hipp.tools.generate_quickviews(PREPROCESSED_IMAGES, QUICKVIEW_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad9f2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhipp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_clahe_to_tif_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/godinlu/Documents/github/ship/hipp/notebooks/data/kh9pc/preprocessed_images/D3C1214-100097A014.tif\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.tif\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/ship/hipp/src/hipp/image.py:291\u001b[39m, in \u001b[36mapply_clahe_to_tif_blockwise\u001b[39m\u001b[34m(input_path, output_path, block_size, clip_limit)\u001b[39m\n\u001b[32m    288\u001b[39m block_float /= \u001b[32m255.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block_float.max() > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (block_float.max() \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m1\u001b[39m)\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# Apply adaptive histogram equalization\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m equalized = \u001b[43mexposure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mequalize_adapthist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_limit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Rescale back to uint8\u001b[39;00m\n\u001b[32m    294\u001b[39m block_out = (equalized * \u001b[32m255\u001b[39m).astype(np.uint8)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/hipp/6cXfZaze/dev/lib/python3.12/site-packages/skimage/color/adapt_rgb.py:41\u001b[39m, in \u001b[36madapt_rgb.<locals>.decorator.<locals>.image_filter_adapted\u001b[39m\u001b[34m(image, *args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_to_rgb(image_filter, image, *args, **kwargs)\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/hipp/6cXfZaze/dev/lib/python3.12/site-packages/skimage/exposure/_adapthist.py:89\u001b[39m, in \u001b[36mequalize_adapthist\u001b[39m\u001b[34m(image, kernel_size, clip_limit, nbins)\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mIncorrect value of `kernel_size`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     87\u001b[39m kernel_size = [\u001b[38;5;28mint\u001b[39m(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kernel_size]\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m image = \u001b[43m_clahe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m image = image.astype(float_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rescale_intensity(image)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/hatch/env/virtual/hipp/6cXfZaze/dev/lib/python3.12/site-packages/skimage/exposure/_adapthist.py:194\u001b[39m, in \u001b[36m_clahe\u001b[39m\u001b[34m(image, kernel_size, clip_limit, nbins)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# calculate interpolation coefficients\u001b[39;00m\n\u001b[32m    191\u001b[39m coeffs = np.meshgrid(\n\u001b[32m    192\u001b[39m     *\u001b[38;5;28mtuple\u001b[39m([np.arange(k) / k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kernel_size[::-\u001b[32m1\u001b[39m]]), indexing=\u001b[33m'\u001b[39m\u001b[33mij\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    193\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m coeffs = [\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m coeffs]\n\u001b[32m    195\u001b[39m inv_coeffs = [\u001b[32m1\u001b[39m - c \u001b[38;5;28;01mfor\u001b[39;00m dim, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(coeffs)]\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# sum over contributions of neighboring contextual\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# regions in each direction\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "hipp.image.apply_clahe_to_tif_blockwise(\"/home/godinlu/Documents/github/ship/hipp/notebooks/data/kh9pc/preprocessed_images/D3C1214-100097A014.tif\", \"test.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5f84a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating quickviews: 100%|██████████| 1/1 [00:55<00:00, 55.27s/image]\n"
     ]
    }
   ],
   "source": [
    "hipp.tools.generate_quickviews(\".\", QUICKVIEW_FACTOR, \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hipp)",
   "language": "python",
   "name": "hipp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
